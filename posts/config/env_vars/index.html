



<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Default Configuration Mode (using Env Vars)</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
    <link href="https://unpkg.com/prismjs@1.20.0/themes/prism-okaidia.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/19.1.1/tooltips.min.css" crossorigin="anonymous" referrerpolicy="no-referrer">
    <style>
html {
    padding: 0;
    margin: 0;
}

body{
    font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    padding: 0;
    margin: 0;
}

footer{
    width: 100%;
	height: 32px;
	font-size: 12px;
	display: flex;
	flex-direction: row;
	justify-content: center;
	gap: 18px;
	align-items: center;
	color: #5d5d5d;
	background: #e9eaeb;
	border-top: 1px solid #c4c5c6;
}

#cookiesManager{
    cursor: pointer;
    color: #485fc7;
}

.page-content {
    display: flex;
    flex-direction: row;
    margin: 0;
    padding: 0;
    overflow: scroll;
    padding: 0;
    margin: 0;
}

header {
    background-color: lightgrey;
    height: 2%;
    padding: 10px;
}

nav {
    padding: 1em;
    min-width: 200px;
}

main {
    flex: 1;
    padding: 0 5em 0 5em;
}

.logotitle {
    font-size: 1.5em;
    font-weight: bold;
    margin: 5px;
}

.number {
    all: unset;
}

.tag.token {
    all: unset;
}

main ul {
    list-style-type: disc;
    padding-left: 30px;
    margin-top: 10px;
}

h1 {
    font-size: 2rem;
    margin-top: 10px;
}

h2 {
    font-size: 1.5rem;
    margin-top: 10px;
    font-weight: 500;
}

h3 {
    font-size: 1rem;
    margin-top: 10px; 
    font-weight: 500;
}
p {
    margin-top: 10px;
}

/* Accessibility styling */

a {
    color: #485fc7;
    text-decoration: underline;
}

.menu-list a {
    text-decoration: none;
}


.token.comment, .token.prolog, .token.doctype, .token.cdata {
    color: #8093a5;
}

.token.property, .token.tag, .token.constant, .token.symbol, .token.deleted {
    color: #ff36ab;
}
</style>
    <script type="module" async="">import mermaid from "https://unpkg.com/mermaid@10/dist/mermaid.esm.min.mjs";document.addEventListener('DOMContentLoaded', mermaid.initialize({"loadOnSave":true}));</script>
    <script>function showTooltip(o,e){o.trigger.className.includes("tooltipped")||(o.trigger.children[0].className="tooltipped tooltipped-s",o.trigger.children[0].ariaLabel=e)}window.addEventListener("load",()=>{var o=new ClipboardJS(".code-copy");o.on("success",o=>showTooltip(o,"Copied!")),o.on("error",o=>showTooltip(o,"Failed..."))});</script>
<script async="" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script>

    
    <script src="https://wcpstatic.microsoft.com/mscc/lib/v2/wcp-consent.js" type="text/javascript"></script>
    <script>
        function onConsentChanged(categoryPreferences) {
            console.log("onConsentChanged", categoryPreferences);        
        }

        var siteConsent

        function initialize(){
          var currentYear = new Date().getFullYear()
          document.getElementById("copyright").innerHTML = `©️ ${currentYear} Microsoft`;
          window.WcpConsent && WcpConsent.init("en-US", "cookie-banner", function (err, _siteConsent) {
              if (!err) {
                  siteConsent = _siteConsent;  //siteConsent is used to get the current consent  
              } else {
                  console.log("Error initializing WcpConsent: "+ err);
              }
          }, onConsentChanged, WcpConsent.themes.light);
        }

        addEventListener("DOMContentLoaded", initialize)
        addEventListener("DOMContentLoaded", checkCookieManager)

        function checkCookieManager(){
          if(siteConsent.isConsentRequired){
            document.getElementById("cookiesManager").style.display = 'block';
            document.getElementById("divider").style.display = 'block';
          }
          else{
            document.getElementById("cookiesManager").style.display = 'none';
            document.getElementById("divider").style.display = 'none';
          }
        }

        function manageConsent() {
        if(siteConsent.isConsentRequired){
            siteConsent.manageConsent();
        }
    }
    </script>
    
  </head>
  <body>
    <header>
        <div id="cookie-banner"></div>
        <a href="/graphrag/"><span class="logotitle">GraphRAG</span></a>
    </header>
    <div class="page-content">
        <!-- Sidebar -->
        <aside class="menu">
          <ul class="menu-list">
            <li>
              
<a href="/graphrag/">Welcome</a>

            </li>

            <!-- Get Started Links -->
            <li>
              
<a href="/graphrag/posts/get_started/">Get Started</a>

              
<a href="/graphrag/posts/developing/">Developing</a>

            </li>

            <!-- Indexing Links -->
            <li>
                
<a href="/graphrag/posts/index/overview/">Indexing</a>

                <ul><li>
<a href="/graphrag/posts/index/0-architecture/">Architecture</a>
</li><li>
<a href="/graphrag/posts/index/1-default_dataflow/">Dataflow</a>
</li><li>
<a href="/graphrag/posts/index/2-cli/">CLI</a>
</li><li>
                    
<a href="/graphrag/posts/config/overview/">Configuration</a>

                    <ul>
                      <li>
<a href="/graphrag/posts/config/init">Init command</a>
</li>
                      <li>
<a href="/graphrag/posts/config/env_vars">Using Env Vars</a>
</li>
                      <li>
<a href="/graphrag/posts/config/json_yaml">Using JSON or YAML</a>
</li>
                      <li>
<a href="/graphrag/posts/config/custom">Fully Custom</a>
</li>
                      <li>
<a href="/graphrag/posts/config/template">Template</a>
</li>
                    </ul>
                  </li>

                  <li>
                    
<a href="/graphrag/posts/prompt_tuning/overview/">Prompt Tuning</a>

                    <ul>
                        <li>
                            
<a href="/graphrag/posts/prompt_tuning/auto_prompt_tuning/">Automatic Templating</a>

                        </li>
                        <li>
                            
<a href="/graphrag/posts/prompt_tuning/manual_prompt_tuning/">Manual Prompt Tuning</a>

                        </li>
                    </ul>
                  </li>
                </ul>
            </li>
            

            <!-- Query Links -->
            <li>
              
<a href="/graphrag/posts/query/overview/">Query</a>

              <ul><li>
<a href="/graphrag/posts/query/1-local_search/">Local Search</a>
</li><li>
<a href="/graphrag/posts/query/2-question_generation/">Question Generation</a>
</li><li>
<a href="/graphrag/posts/query/0-global_search/">Global Search</a>
</li><li>
<a href="/graphrag/posts/query/3-cli/">CLI</a>
</li><li>
                  
<a href="/graphrag/posts/query/notebooks/overview/">Notebooks</a>

                  <ul>
                    <li>
<a href="/graphrag/posts/query/notebooks/global_search_nb">Global Search</a>
</li>
                    <li>
<a href="/graphrag/posts/query/notebooks/local_search_nb">Local Search</a>
</li>
                  </ul>
                </li>
            </ul>
            </li>
          </ul>
        </aside>

        <!-- Main Content -->
        <main>
            <h1>Default Configuration Mode (using Env Vars)</h1>
            <h2>Text-Embeddings Customization</h2>
<p>By default, the GraphRAG indexer will only emit embeddings required for our query methods. However, the model has embeddings defined for all plaintext fields, and these can be generated by setting the <code>GRAPHRAG_EMBEDDING_TARGET</code> environment variable to <code>all</code>.</p>
<p>If the embedding target is <code>all</code>, and you want to only embed a subset of these fields, you may specify which embeddings to skip using the <code>GRAPHRAG_EMBEDDING_SKIP</code> argument described below.</p>
<h3>Embedded Fields</h3>
<ul>
<li><code>text_unit.text</code></li>
<li><code>document.raw_content</code></li>
<li><code>entity.name</code></li>
<li><code>entity.description</code></li>
<li><code>relationship.description</code></li>
<li><code>community.title</code></li>
<li><code>community.summary</code></li>
<li><code>community.full_content</code></li>
</ul>
<h2>Input Data</h2>
<p>Our pipeline can ingest .csv or .txt data from an input folder. These files can be nested within subfolders. To configure how input data is handled, what fields are mapped over, and how timestamps are parsed, look for configuration values starting with <code>GRAPHRAG_INPUT_</code> below. In general, CSV-based data provides the most customizeability. Each CSV should at least contain a <code>text</code> field (which can be mapped with environment variables), but it's helpful if they also have <code>title</code>, <code>timestamp</code>, and <code>source</code> fields. Additional fields can be included as well, which will land as extra fields on the <code>Document</code> table.</p>
<h2>Base LLM Settings</h2>
<p>These are the primary settings for configuring LLM connectivity.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required?</th>
<th>Description</th>
<th>Type</th>
<th>Default Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_API_KEY</code></td>
<td><strong>Yes for OpenAI. Optional for AOAI</strong></td>
<td>The API key. (Note: `OPENAI_API_KEY is also used as a fallback). If not defined when using AOAI, managed identity will be used.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_API_BASE</code></td>
<td><strong>For AOAI</strong></td>
<td>The API Base URL</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_API_VERSION</code></td>
<td><strong>For AOAI</strong></td>
<td>The AOAI API version.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_API_ORGANIZATION</code></td>
<td></td>
<td>The AOAI organization.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_API_PROXY</code></td>
<td></td>
<td>The AOAI proxy.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<h2>Text Generation Settings</h2>
<p>These settings control the text generation model used by the pipeline. Any settings with a fallback will use the base LLM settings, if available.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required?</th>
<th>Description</th>
<th>Type</th>
<th>Default Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_LLM_TYPE</code></td>
<td><strong>For AOAI</strong></td>
<td>The LLM operation type. Either <code>openai_chat</code> or <code>azure_openai_chat</code></td>
<td><code>str</code></td>
<td><code>openai_chat</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_DEPLOYMENT_NAME</code></td>
<td><strong>For AOAI</strong></td>
<td>The AOAI model deployment name.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_API_KEY</code></td>
<td>Yes (uses fallback)</td>
<td>The API key. If not defined when using AOAI, managed identity will be used.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_API_BASE</code></td>
<td>For AOAI (uses fallback)</td>
<td>The API Base URL</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_API_VERSION</code></td>
<td>For AOAI (uses fallback)</td>
<td>The AOAI API version.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_API_ORGANIZATION</code></td>
<td>For AOAI (uses fallback)</td>
<td>The AOAI organization.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_API_PROXY</code></td>
<td></td>
<td>The AOAI proxy.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_MODEL</code></td>
<td></td>
<td>The LLM model.</td>
<td><code>str</code></td>
<td><code>gpt-4-turbo-preview</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_MAX_TOKENS</code></td>
<td></td>
<td>The maximum number of tokens.</td>
<td><code>int</code></td>
<td><code>4000</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_REQUEST_TIMEOUT</code></td>
<td></td>
<td>The maximum number of seconds to wait for a response from the chat client.</td>
<td><code>int</code></td>
<td><code>180</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_MODEL_SUPPORTS_JSON</code></td>
<td></td>
<td>Indicates whether the given model supports JSON output mode. <code>True</code> to enable.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_THREAD_COUNT</code></td>
<td></td>
<td>The number of threads to use for LLM parallelization.</td>
<td><code>int</code></td>
<td>50</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_THREAD_STAGGER</code></td>
<td></td>
<td>The time to wait (in seconds) between starting each thread.</td>
<td><code>float</code></td>
<td>0.3</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_CONCURRENT_REQUESTS</code></td>
<td></td>
<td>The number of concurrent requests to allow for the embedding client.</td>
<td><code>int</code></td>
<td>25</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_TOKENS_PER_MINUTE</code></td>
<td></td>
<td>The number of tokens per minute to allow for the LLM client. 0 = Bypass</td>
<td><code>int</code></td>
<td>0</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_REQUESTS_PER_MINUTE</code></td>
<td></td>
<td>The number of requests per minute to allow for the LLM client. 0 = Bypass</td>
<td><code>int</code></td>
<td>0</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_MAX_RETRIES</code></td>
<td></td>
<td>The maximum number of retries to attempt when a request fails.</td>
<td><code>int</code></td>
<td>10</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_MAX_RETRY_WAIT</code></td>
<td></td>
<td>The maximum number of seconds to wait between retries.</td>
<td><code>int</code></td>
<td>10</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_SLEEP_ON_RATE_LIMIT_RECOMMENDATION</code></td>
<td></td>
<td>Whether to sleep on rate limit recommendation. (Azure Only)</td>
<td><code>bool</code></td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_TEMPERATURE</code></td>
<td></td>
<td>The temperature to use generation.</td>
<td><code>float</code></td>
<td>0</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_TOP_P</code></td>
<td></td>
<td>The top_p to use for sampling.</td>
<td><code>float</code></td>
<td>1</td>
</tr>
<tr>
<td><code>GRAPHRAG_LLM_N</code></td>
<td></td>
<td>The number of responses to generate.</td>
<td><code>int</code></td>
<td>1</td>
</tr>
</tbody>
</table>
<h2>Text Embedding Settings</h2>
<p>These settings control the text embedding model used by the pipeline. Any settings with a fallback will use the base LLM settings, if available.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required ?</th>
<th>Description</th>
<th>Type</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_EMBEDDING_TYPE</code></td>
<td><strong>For AOAI</strong></td>
<td>The embedding client to use. Either <code>openai_embedding</code> or <code>azure_openai_embedding</code></td>
<td><code>str</code></td>
<td><code>openai_embedding</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_DEPLOYMENT_NAME</code></td>
<td><strong>For AOAI</strong></td>
<td>The AOAI deployment name.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_API_KEY</code></td>
<td>Yes (uses fallback)</td>
<td>The API key to use for the embedding client. If not defined when using AOAI, managed identity will be used.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_API_BASE</code></td>
<td>For AOAI (uses fallback)</td>
<td>The API base URL.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_API_VERSION</code></td>
<td>For AOAI (uses fallback)</td>
<td>The AOAI API version to use for the embedding client.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_API_ORGANIZATION</code></td>
<td>For AOAI (uses fallback)</td>
<td>The AOAI organization to use for the embedding client.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_API_PROXY</code></td>
<td></td>
<td>The AOAI proxy to use for the embedding client.</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_MODEL</code></td>
<td></td>
<td>The model to use for the embedding client.</td>
<td><code>str</code></td>
<td><code>text-embedding-3-small</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_BATCH_SIZE</code></td>
<td></td>
<td>The number of texts to embed at once. <a href="https://learn.microsoft.com/en-us/azure/ai-ce">(Azure limit is 16)</a></td>
<td><code>int</code></td>
<td>16</td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_BATCH_MAX_TOKENS</code></td>
<td></td>
<td>The maximum tokens per batch <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/reference">(Azure limit is 8191)</a></td>
<td><code>int</code></td>
<td>8191</td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_TARGET</code></td>
<td></td>
<td>The target fields to embed. Either <code>required</code> or <code>all</code>.</td>
<td><code>str</code></td>
<td><code>required</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_SKIP</code></td>
<td></td>
<td>A comma-separated list of fields to skip embeddings for . (e.g. 'relationship.description')</td>
<td><code>str</code></td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_THREAD_COUNT</code></td>
<td></td>
<td>The number of threads to use for parallelization for embeddings.</td>
<td><code>int</code></td>
<td></td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_THREAD_STAGGER</code></td>
<td></td>
<td>The time to wait (in seconds) between starting each thread for embeddings.</td>
<td><code>float</code></td>
<td>50</td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_CONCURRENT_REQUESTS</code></td>
<td></td>
<td>The number of concurrent requests to allow for the embedding client.</td>
<td><code>int</code></td>
<td>25</td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_TOKENS_PER_MINUTE</code></td>
<td></td>
<td>The number of tokens per minute to allow for the embedding client. 0 = Bypass</td>
<td><code>int</code></td>
<td>0</td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_REQUESTS_PER_MINUTE</code></td>
<td></td>
<td>The number of requests per minute to allow for the embedding client. 0 = Bypass</td>
<td><code>int</code></td>
<td>0</td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_MAX_RETRIES</code></td>
<td></td>
<td>The maximum number of retries to attempt when a request fails.</td>
<td><code>int</code></td>
<td>10</td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_MAX_RETRY_WAIT</code></td>
<td></td>
<td>The maximum number of seconds to wait between retries.</td>
<td><code>int</code></td>
<td>10</td>
</tr>
<tr>
<td><code>GRAPHRAG_EMBEDDING_SLEEP_ON_RATE_LIMIT_RECOMMENDATION</code></td>
<td></td>
<td>Whether to sleep on rate limit recommendation. (Azure Only)</td>
<td><code>bool</code></td>
<td><code>True</code></td>
</tr>
</tbody>
</table>
<h2>Input Settings</h2>
<p>These settings control the data input used by the pipeline. Any settings with a fallback will use the base LLM settings, if available.</p>
<h3>Plaintext Input Data (<code>GRAPHRAG_INPUT_FILE_TYPE</code>=text)</h3>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_INPUT_FILE_PATTERN</code></td>
<td>The file pattern regexp to use when reading input files from the input directory.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>.*\.txt$</code></td>
</tr>
</tbody>
</table>
<h3>CSV Input Data (<code>GRAPHRAG_INPUT_FILE_TYPE</code>=csv)</h3>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_INPUT_TYPE</code></td>
<td>The input storage type to use when reading files. (<code>file</code> or <code>blob</code>)</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>file</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_FILE_PATTERN</code></td>
<td>The file pattern regexp to use when reading input files from the input directory.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>.*\.txt$</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_SOURCE_COLUMN</code></td>
<td>The 'source' column to use when reading CSV input files.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>source</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_TIMESTAMP_COLUMN</code></td>
<td>The 'timestamp' column to use when reading CSV input files.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_TIMESTAMP_FORMAT</code></td>
<td>The timestamp format to use when parsing timestamps in the timestamp column.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_TEXT_COLUMN</code></td>
<td>The 'text' column to use when reading CSV input files.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>text</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_DOCUMENT_ATTRIBUTE_COLUMNS</code></td>
<td>A list of CSV columns, comma-separated, to incorporate as document fields.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>id</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_TITLE_COLUMN</code></td>
<td>The 'title' column to use when reading CSV input files.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>title</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_STORAGE_ACCOUNT_BLOB_URL</code></td>
<td>The Azure Storage blob endpoint to use when in <code>blob</code> mode and using managed identity. Will have the format <code>https://&lt;storage_account_name&gt;.blob.core.windows.net</code></td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_CONNECTION_STRING</code></td>
<td>The connection string to use when reading CSV input files from Azure Blob Storage.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_CONTAINER_NAME</code></td>
<td>The container name to use when reading CSV input files from Azure Blob Storage.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_BASE_DIR</code></td>
<td>The base directory to read input files from.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
</tbody>
</table>
<h2>Data Mapping Settings</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_INPUT_FILE_TYPE</code></td>
<td>The type of input data, <code>csv</code> or <code>text</code></td>
<td><code>str</code></td>
<td>optional</td>
<td><code>text</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_INPUT_ENCODING</code></td>
<td>The encoding to apply when reading CSV/text input files.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>utf-8</code></td>
</tr>
</tbody>
</table>
<h2>Data Chunking</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_CHUNK_SIZE</code></td>
<td>The chunk size in tokens for text-chunk analysis windows.</td>
<td><code>str</code></td>
<td>optional</td>
<td>1200</td>
</tr>
<tr>
<td><code>GRAPHRAG_CHUNK_OVERLAP</code></td>
<td>The chunk overlap in tokens for text-chunk analysis windows.</td>
<td><code>str</code></td>
<td>optional</td>
<td>100</td>
</tr>
<tr>
<td><code>GRAPHRAG_CHUNK_BY_COLUMNS</code></td>
<td>A comma-separated list of document attributes to groupby when performing TextUnit chunking.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>id</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_CHUNK_ENCODING_MODEL</code></td>
<td>The encoding model to use for chunking.</td>
<td><code>str</code></td>
<td>optional</td>
<td>The top-level encoding model.</td>
</tr>
</tbody>
</table>
<h2>Prompting Overrides</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_ENTITY_EXTRACTION_PROMPT_FILE</code></td>
<td>The path (relative to the root) of an entity extraction prompt template text file.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_ENTITY_EXTRACTION_MAX_GLEANINGS</code></td>
<td>The maximum number of redrives (gleanings) to invoke when extracting entities in a loop.</td>
<td><code>int</code></td>
<td>optional</td>
<td>1</td>
</tr>
<tr>
<td><code>GRAPHRAG_ENTITY_EXTRACTION_ENTITY_TYPES</code></td>
<td>A comma-separated list of entity types to extract.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>organization,person,event,geo</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_ENTITY_EXTRACTION_ENCODING_MODEL</code></td>
<td>The encoding model to use for entity extraction.</td>
<td><code>str</code></td>
<td>optional</td>
<td>The top-level encoding model.</td>
</tr>
<tr>
<td><code>GRAPHRAG_SUMMARIZE_DESCRIPTIONS_PROMPT_FILE</code></td>
<td>The path (relative to the root) of an description summarization prompt template text file.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_SUMMARIZE_DESCRIPTIONS_MAX_LENGTH</code></td>
<td>The maximum number of tokens to generate per description summarization.</td>
<td><code>int</code></td>
<td>optional</td>
<td>500</td>
</tr>
<tr>
<td><code>GRAPHRAG_CLAIM_EXTRACTION_ENABLED</code></td>
<td>Whether claim extraction is enabled for this pipeline.</td>
<td><code>bool</code></td>
<td>optional</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_CLAIM_EXTRACTION_DESCRIPTION</code></td>
<td>The claim_description prompting argument to utilize.</td>
<td><code>string</code></td>
<td>optional</td>
<td>&quot;Any claims or facts that could be relevant to threat analysis.&quot;</td>
</tr>
<tr>
<td><code>GRAPHRAG_CLAIM_EXTRACTION_PROMPT_FILE</code></td>
<td>The claim extraction prompt to utilize.</td>
<td><code>string</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_CLAIM_EXTRACTION_MAX_GLEANINGS</code></td>
<td>The maximum number of redrives (gleanings) to invoke when extracting claims in a loop.</td>
<td><code>int</code></td>
<td>optional</td>
<td>1</td>
</tr>
<tr>
<td><code>GRAPHRAG_CLAIM_EXTRACTION_ENCODING_MODEL</code></td>
<td>The encoding model to use for claim extraction.</td>
<td><code>str</code></td>
<td>optional</td>
<td>The top-level encoding model</td>
</tr>
<tr>
<td><code>GRAPHRAG_COMMUNITY_REPORTS_PROMPT_FILE</code></td>
<td>The community reports extraction prompt to utilize.</td>
<td><code>string</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_COMMUNITY_REPORTS_MAX_LENGTH</code></td>
<td>The maximum number of tokens to generate per community reports.</td>
<td><code>int</code></td>
<td>optional</td>
<td>1500</td>
</tr>
</tbody>
</table>
<h2>Storage</h2>
<p>This section controls the storage mechanism used by the pipeline used for emitting output tables.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_STORAGE_TYPE</code></td>
<td>The type of reporter to use. Options are <code>file</code>, <code>memory</code>, or <code>blob</code></td>
<td><code>str</code></td>
<td>optional</td>
<td><code>file</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_STORAGE_STORAGE_ACCOUNT_BLOB_URL</code></td>
<td>The Azure Storage blob endpoint to use when in <code>blob</code> mode and using managed identity. Will have the format <code>https://&lt;storage_account_name&gt;.blob.core.windows.net</code></td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_STORAGE_CONNECTION_STRING</code></td>
<td>The Azure Storage connection string to use when in <code>blob</code> mode.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_STORAGE_CONTAINER_NAME</code></td>
<td>The Azure Storage container name to use when in <code>blob</code> mode.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_STORAGE_BASE_DIR</code></td>
<td>The base path to data outputs outputs.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
</tbody>
</table>
<h2>Cache</h2>
<p>This section controls the cache mechanism used by the pipeline. This is used to cache LLM invocation results.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_CACHE_TYPE</code></td>
<td>The type of cache to use. Options are <code>file</code>, <code>memory</code>, <code>none</code> or <code>blob</code></td>
<td><code>str</code></td>
<td>optional</td>
<td><code>file</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_CACHE_STORAGE_ACCOUNT_BLOB_URL</code></td>
<td>The Azure Storage blob endpoint to use when in <code>blob</code> mode and using managed identity. Will have the format <code>https://&lt;storage_account_name&gt;.blob.core.windows.net</code></td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_CACHE_CONNECTION_STRING</code></td>
<td>The Azure Storage connection string to use when in <code>blob</code> mode.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_CACHE_CONTAINER_NAME</code></td>
<td>The Azure Storage container name to use when in <code>blob</code> mode.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_CACHE_BASE_DIR</code></td>
<td>The base path to the reporting outputs.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
</tbody>
</table>
<h2>Reporting</h2>
<p>This section controls the reporting mechanism used by the pipeline, for common events and error messages. The default is to write reports to a file in the output directory. However, you can also choose to write reports to the console or to an Azure Blob Storage container.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_REPORTING_TYPE</code></td>
<td>The type of reporter to use. Options are <code>file</code>, <code>console</code>, or <code>blob</code></td>
<td><code>str</code></td>
<td>optional</td>
<td><code>file</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_REPORTING_STORAGE_ACCOUNT_BLOB_URL</code></td>
<td>The Azure Storage blob endpoint to use when in <code>blob</code> mode and using managed identity. Will have the format <code>https://&lt;storage_account_name&gt;.blob.core.windows.net</code></td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_REPORTING_CONNECTION_STRING</code></td>
<td>The Azure Storage connection string to use when in <code>blob</code> mode.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_REPORTING_CONTAINER_NAME</code></td>
<td>The Azure Storage container name to use when in <code>blob</code> mode.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
<tr>
<td><code>GRAPHRAG_REPORTING_BASE_DIR</code></td>
<td>The base path to the reporting outputs.</td>
<td><code>str</code></td>
<td>optional</td>
<td>None</td>
</tr>
</tbody>
</table>
<h2>Node2Vec Parameters</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_NODE2VEC_ENABLED</code></td>
<td>Whether to enable Node2Vec</td>
<td><code>bool</code></td>
<td>optional</td>
<td>False</td>
</tr>
<tr>
<td><code>GRAPHRAG_NODE2VEC_NUM_WALKS</code></td>
<td>The Node2Vec number of walks to perform</td>
<td><code>int</code></td>
<td>optional</td>
<td>10</td>
</tr>
<tr>
<td><code>GRAPHRAG_NODE2VEC_WALK_LENGTH</code></td>
<td>The Node2Vec walk length</td>
<td><code>int</code></td>
<td>optional</td>
<td>40</td>
</tr>
<tr>
<td><code>GRAPHRAG_NODE2VEC_WINDOW_SIZE</code></td>
<td>The Node2Vec window size</td>
<td><code>int</code></td>
<td>optional</td>
<td>2</td>
</tr>
<tr>
<td><code>GRAPHRAG_NODE2VEC_ITERATIONS</code></td>
<td>The number of iterations to run node2vec</td>
<td><code>int</code></td>
<td>optional</td>
<td>3</td>
</tr>
<tr>
<td><code>GRAPHRAG_NODE2VEC_RANDOM_SEED</code></td>
<td>The random seed to use for node2vec</td>
<td><code>int</code></td>
<td>optional</td>
<td>597832</td>
</tr>
</tbody>
</table>
<h2>Data Snapshotting</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_SNAPSHOT_GRAPHML</code></td>
<td>Whether to enable GraphML snapshots.</td>
<td><code>bool</code></td>
<td>optional</td>
<td>False</td>
</tr>
<tr>
<td><code>GRAPHRAG_SNAPSHOT_RAW_ENTITIES</code></td>
<td>Whether to enable raw entity snapshots.</td>
<td><code>bool</code></td>
<td>optional</td>
<td>False</td>
</tr>
<tr>
<td><code>GRAPHRAG_SNAPSHOT_TOP_LEVEL_NODES</code></td>
<td>Whether to enable top-level node snapshots.</td>
<td><code>bool</code></td>
<td>optional</td>
<td>False</td>
</tr>
</tbody>
</table>
<h1>Miscellaneous Settings</h1>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Type</th>
<th>Required or Optional</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GRAPHRAG_ASYNC_MODE</code></td>
<td>Which async mode to use. Either <code>asyncio</code> or <code>threaded</code>.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>asyncio</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_ENCODING_MODEL</code></td>
<td>The text encoding model, used in tiktoken, to encode text.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>cl100k_base</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_MAX_CLUSTER_SIZE</code></td>
<td>The maximum number of entities to include in a single Leiden cluster.</td>
<td><code>int</code></td>
<td>optional</td>
<td>10</td>
</tr>
<tr>
<td><code>GRAPHRAG_SKIP_WORKFLOWS</code></td>
<td>A comma-separated list of workflow names to skip.</td>
<td><code>str</code></td>
<td>optional</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>GRAPHRAG_UMAP_ENABLED</code></td>
<td>Whether to enable UMAP layouts</td>
<td><code>bool</code></td>
<td>optional</td>
<td>False</td>
</tr>
</tbody>
</table>

        </main>
    </div>
    <footer>
      <a href="https://go.microsoft.com/fwlink/?LinkId=521839">Privacy</a>
      |
      <a href="https://go.microsoft.com/fwlink/?LinkId=2259814">Consumer Health Privacy</a>
      |
      <span id="cookiesManager" onClick="manageConsent();">Cookies</span>
      <span id="divider">|</span>
      <a href="https://go.microsoft.com/fwlink/?LinkID=206977">Terms of Use</a>
      |
      <a href="https://www.microsoft.com/trademarks">Trademarks</a>
      |
      <a href="https://www.microsoft.com" id="copyright"></a>
      |
      <a href="https://github.com/microsoft/graphrag">GitHub</a>
      |
      <a href="https://github.com/Azure-Samples/graphrag-accelerator">Solution Accelerator</a>
    </footer>    
  </body>
</html>