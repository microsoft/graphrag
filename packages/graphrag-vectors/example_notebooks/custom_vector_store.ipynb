{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring-Your-Own Vector Store\n",
    "\n",
    "This notebook demonstrates how to implement a custom vector store and register for usage with GraphRAG.\n",
    "\n",
    "## Overview\n",
    "\n",
    "GraphRAG uses a plug-and-play architecture that allow for easy integration of custom vector stores (outside of what is natively supported) by following a factory design pattern. This allows you to:\n",
    "\n",
    "- **Extend functionality**: Add support for new vector database backends\n",
    "- **Customize behavior**: Implement specialized search logic or data structures\n",
    "- **Integrate existing systems**: Connect GraphRAG to your existing vector database infrastructure\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. Understanding the `VectorStore` interface\n",
    "2. Implementing a custom vector store class\n",
    "3. Registering your vector store with the `VectorStoreFactory`\n",
    "4. Testing and validating your implementation\n",
    "5. Configuring GraphRAG to use your custom vector store\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Dependencies\n",
    "\n",
    "First, let's import the necessary GraphRAG components and other dependencies we'll need.\n",
    "\n",
    "```bash\n",
    "pip install graphrag\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Understand the VectorStore Interface\n",
    "\n",
    "Before using a custom vector store, let's examine the `VectorStore` interface to understand what methods need to be implemented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore Abstract Methods:\n",
      "================================================================================\n",
      "\n",
      "connect:\n",
      "  (self) -> None\n",
      "\n",
      "create_index:\n",
      "  (self) -> None\n",
      "\n",
      "load_documents:\n",
      "  (self, documents: list[graphrag_vectors.vector_store.VectorStoreDocument]) -> None\n",
      "\n",
      "search_by_id:\n",
      "  (self, id: str) -> graphrag_vectors.vector_store.VectorStoreDocument\n",
      "\n",
      "similarity_search_by_vector:\n",
      "  (self, query_embedding: list[float], k: int = 10) -> list[graphrag_vectors.vector_store.VectorStoreSearchResult]\n",
      "\n",
      "Total abstract methods to implement: 5\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "# Let's inspect the VectorStore class to understand the required methods\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from graphrag_vectors import (\n",
    "    IndexSchema,\n",
    "    TextEmbedder,\n",
    "    VectorStore,\n",
    "    VectorStoreConfig,\n",
    "    VectorStoreDocument,\n",
    "    VectorStoreSearchResult,\n",
    "    create_vector_store,\n",
    "    register_vector_store,\n",
    ")\n",
    "\n",
    "print(\"VectorStore Abstract Methods:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "abstract_methods = []\n",
    "for name, method in inspect.getmembers(VectorStore, predicate=inspect.isfunction):\n",
    "    if getattr(method, \"__isabstractmethod__\", False):\n",
    "        abstract_methods.append(name)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  {inspect.signature(method)}\")\n",
    "\n",
    "print(f\"\\nTotal abstract methods to implement: {len(abstract_methods)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implement a Custom Vector Store\n",
    "\n",
    "Now let's implement a simple in-memory vector store as an example. This vector store will:\n",
    "\n",
    "- Store documents and vectors in memory using Python data structures\n",
    "- Support all required VectorStore methods\n",
    "\n",
    "**Note**: This is a simplified example for demonstration. Production vector stores would typically use optimized libraries like FAISS, more sophisticated indexing, and persistent storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInMemoryVectorStore(VectorStore):\n",
    "    \"\"\"A simple in-memory vector store implementation for demonstration purposes.\n",
    "\n",
    "    This vector store stores documents and their embeddings in memory and provides\n",
    "    basic similarity search functionality using cosine similarity.\n",
    "\n",
    "    WARNING: This is for demonstration only - not suitable for production use.\n",
    "    For production, consider using optimized vector databases like LanceDB,\n",
    "    Azure AI Search, or other specialized vector stores.\n",
    "    \"\"\"\n",
    "\n",
    "    # Internal storage for documents and vectors\n",
    "    documents: dict[str, VectorStoreDocument]\n",
    "    vectors: dict[str, np.ndarray]\n",
    "    connected: bool\n",
    "\n",
    "    def __init__(self, custom_config_option: str, **kwargs: Any):\n",
    "        \"\"\"Initialize the in-memory vector store.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Not actually used in this simple implementation, but included to show\n",
    "        # how custom configuration options can be passed.\n",
    "        self.custom_config_option = custom_config_option\n",
    "\n",
    "        self.documents: dict[str, VectorStoreDocument] = {}\n",
    "        self.vectors: dict[str, np.ndarray] = {}\n",
    "        self.connected = False\n",
    "\n",
    "    def connect(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Connect to the vector store (simulated for in-memory store).\"\"\"\n",
    "        print(\"Connecting to in-memory vector store...\")\n",
    "        self.connected = True\n",
    "        print(\"Connected successfully!\")\n",
    "\n",
    "    def create_index(self, **kwargs: Any) -> None:\n",
    "        \"\"\"Create an index (simulated for in-memory store).\n",
    "\n",
    "        In a real vector database, this would create the necessary data structures\n",
    "        and indexes for efficient vector search.\n",
    "        \"\"\"\n",
    "        print(f\"Creating index: {self.index_name}\")\n",
    "        # For in-memory store, we just ensure our storage dictionaries are ready\n",
    "        if not isinstance(self.documents, dict):\n",
    "            self.documents = {}\n",
    "        if not isinstance(self.vectors, dict):\n",
    "            self.vectors = {}\n",
    "        print(\"Index created successfully!\")\n",
    "\n",
    "    def load_documents(\n",
    "        self, documents: list[VectorStoreDocument], overwrite: bool = False\n",
    "    ) -> None:\n",
    "        \"\"\"Load documents into the vector store.\"\"\"\n",
    "        if not self.connected:\n",
    "            msg = \"Vector store is not connected. Call connect() first.\"\n",
    "            raise RuntimeError(msg)\n",
    "        if overwrite:\n",
    "            print(\"Clearing existing documents...\")\n",
    "            self.documents.clear()\n",
    "            self.vectors.clear()\n",
    "\n",
    "        print(f\"Loading {len(documents)} documents...\")\n",
    "        for doc in documents:\n",
    "            self.documents[doc.id] = doc\n",
    "            if doc.vector:\n",
    "                self.vectors[doc.id] = np.array(doc.vector)\n",
    "\n",
    "        print(f\"Successfully loaded {len(documents)} documents!\")\n",
    "\n",
    "    def similarity_search_by_vector(\n",
    "        self, query_embedding: list[float], k: int = 10, **kwargs: Any\n",
    "    ) -> list[VectorStoreSearchResult]:\n",
    "        \"\"\"Search for similar documents using a query vector.\"\"\"\n",
    "        if not self.connected:\n",
    "            msg = \"Vector store is not connected. Call connect() first.\"\n",
    "            raise RuntimeError(msg)\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "\n",
    "        query_vector = np.array(query_embedding)\n",
    "\n",
    "        # Calculate cosine similarity for all documents\n",
    "        similarities = []\n",
    "        for doc_id, doc_vector in self.vectors.items():\n",
    "            # Cosine similarity\n",
    "            similarity = np.dot(query_vector, doc_vector) / (\n",
    "                np.linalg.norm(query_vector) * np.linalg.norm(doc_vector)\n",
    "            )\n",
    "            similarities.append((doc_id, similarity))\n",
    "\n",
    "        # Sort by similarity (highest first) and take top k\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_results = similarities[:k]\n",
    "\n",
    "        # Convert to search results\n",
    "        results = []\n",
    "        for doc_id, score in top_results:\n",
    "            doc = self.documents[doc_id]\n",
    "            results.append(VectorStoreSearchResult(document=doc, score=float(score)))\n",
    "\n",
    "        return results\n",
    "\n",
    "    def similarity_search_by_text(\n",
    "        self,\n",
    "        text: str,\n",
    "        text_embedder: TextEmbedder,\n",
    "        k: int = 10,\n",
    "        **kwargs: Any,\n",
    "    ) -> list[VectorStoreSearchResult]:\n",
    "        \"\"\"Search for similar documents using a text query.\"\"\"\n",
    "        # Embed the query text\n",
    "        query_embedding = text_embedder(text)\n",
    "\n",
    "        # Use vector search\n",
    "        return self.similarity_search_by_vector(query_embedding, k, **kwargs)\n",
    "\n",
    "    def search_by_id(self, id: str) -> VectorStoreDocument:\n",
    "        \"\"\"Retrieve a document by its ID.\"\"\"\n",
    "        return self.documents[id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Register the Custom Vector Store\n",
    "\n",
    "Now let's register our custom vector store with the `VectorStoreFactory` so it can be used throughout GraphRAG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered custom vector store with type: 'simple_memory'\n"
     ]
    }
   ],
   "source": [
    "# Register our custom vector store with a unique identifier\n",
    "CUSTOM_VECTOR_STORE_TYPE = \"simple_memory\"\n",
    "\n",
    "# Register the vector store class\n",
    "register_vector_store(CUSTOM_VECTOR_STORE_TYPE, SimpleInMemoryVectorStore)\n",
    "\n",
    "print(f\"‚úÖ Registered custom vector store with type: '{CUSTOM_VECTOR_STORE_TYPE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test the Custom Vector Store\n",
    "\n",
    "Let's create some sample data and test our custom vector store implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Created 4 sample documents\n"
     ]
    }
   ],
   "source": [
    "# Create sample documents with mock embeddings\n",
    "def create_mock_embedding(dimension: int = 384) -> list[float]:\n",
    "    \"\"\"Create a random embedding vector for testing.\"\"\"\n",
    "    return np.random.normal(0, 1, dimension).tolist()\n",
    "\n",
    "\n",
    "# Sample documents\n",
    "sample_documents = [\n",
    "    VectorStoreDocument(\n",
    "        id=\"doc_1\",\n",
    "        vector=create_mock_embedding(),\n",
    "    ),\n",
    "    VectorStoreDocument(\n",
    "        id=\"doc_2\",\n",
    "        vector=create_mock_embedding(),\n",
    "    ),\n",
    "    VectorStoreDocument(\n",
    "        id=\"doc_3\",\n",
    "        vector=create_mock_embedding(),\n",
    "    ),\n",
    "    VectorStoreDocument(\n",
    "        id=\"doc_4\",\n",
    "        vector=create_mock_embedding(),\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"üìù Created {len(sample_documents)} sample documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created vector store instance: SimpleInMemoryVectorStore\n"
     ]
    }
   ],
   "source": [
    "# Test creating vector store using the factory\n",
    "schema = IndexSchema(index_name=\"test_collection\")\n",
    "\n",
    "# Create vector store instance using factory\n",
    "vector_store: VectorStore = create_vector_store(\n",
    "    VectorStoreConfig(\n",
    "        type=CUSTOM_VECTOR_STORE_TYPE,\n",
    "        custom_config_option=\"example_value\",  # type: ignore\n",
    "    ),\n",
    "    schema,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created vector store instance: {type(vector_store).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to in-memory vector store...\n",
      "Connected successfully!\n",
      "Creating index: test_collection\n",
      "Index created successfully!\n",
      "Loading 4 documents...\n",
      "Successfully loaded 4 documents!\n"
     ]
    }
   ],
   "source": [
    "# Connect and load documents\n",
    "vector_store.connect()\n",
    "vector_store.create_index()\n",
    "vector_store.load_documents(sample_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 3 similar documents:\n",
      "\n",
      "1. ID: doc_3\n",
      "   Similarity Score: 0.0648\n",
      "\n",
      "2. ID: doc_2\n",
      "   Similarity Score: -0.0071\n",
      "\n",
      "3. ID: doc_1\n",
      "   Similarity Score: -0.0293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test similarity search\n",
    "query_vector = create_mock_embedding()  # Random query vector for testing\n",
    "\n",
    "search_results = vector_store.similarity_search_by_vector(\n",
    "    query_vector,\n",
    "    k=3,  # Get top 3 similar documents\n",
    ")\n",
    "\n",
    "print(f\"üîç Found {len(search_results)} similar documents:\\n\")\n",
    "\n",
    "for i, result in enumerate(search_results, 1):\n",
    "    doc = result.document\n",
    "    print(f\"{i}. ID: {doc.id}\")\n",
    "    print(f\"   Similarity Score: {result.score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found document by ID:\n",
      "   ID: doc_2\n"
     ]
    }
   ],
   "source": [
    "# Test search by ID\n",
    "try:\n",
    "    found_doc = vector_store.search_by_id(\"doc_2\")\n",
    "    print(\"‚úÖ Found document by ID:\")\n",
    "    print(f\"   ID: {found_doc.id}\")\n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Configuration for GraphRAG\n",
    "\n",
    "Now let's see how you would configure GraphRAG to use your custom vector store in a settings file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Example settings.yml configuration:\n",
      "========================================\n",
      "models:\n",
      "  default_embedding_model:\n",
      "    model: text-embedding-3-small\n",
      "    model_provider: openai\n",
      "    type: embedding\n",
      "vector_store:\n",
      "  custom_config_option: example_value\n",
      "  type: simple_memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example GraphRAG yaml settings\n",
    "example_settings = {\n",
    "    \"vector_store\": {\n",
    "        \"type\": CUSTOM_VECTOR_STORE_TYPE,  # \"simple_memory\"\n",
    "        # Add any custom parameters your vector store needs\n",
    "        \"custom_config_option\": \"example_value\",\n",
    "    },\n",
    "    # Other GraphRAG configuration...\n",
    "    \"models\": {\n",
    "        \"default_embedding_model\": {\n",
    "            \"type\": \"embedding\",\n",
    "            \"model_provider\": \"openai\",\n",
    "            \"model\": \"text-embedding-3-small\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# Convert to YAML format for settings.yml\n",
    "yaml_config = yaml.dump(example_settings, default_flow_style=False, indent=2)\n",
    "\n",
    "print(\"üìÑ Example settings.yml configuration:\")\n",
    "print(\"=\" * 40)\n",
    "print(yaml_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Integration with GraphRAG Pipeline\n",
    "\n",
    "Here's how your custom vector store would be used in a typical GraphRAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Simulating GraphRAG pipeline with custom vector store...\n",
      "\n",
      "Connecting to in-memory vector store...\n",
      "Connected successfully!\n",
      "Creating index: graphrag_entities\n",
      "Index created successfully!\n",
      "‚úÖ Step 1: Vector store created and connected\n",
      "Loading 10 documents...\n",
      "Successfully loaded 10 documents!\n",
      "‚úÖ Step 2: Loaded 10 entity documents\n",
      "‚úÖ Step 3: Found 5 relevant entities for query\n",
      "‚úÖ Step 4: Context built using retrieved entities\n",
      "\n",
      "üéØ Retrieved 5 entities for context building\n"
     ]
    }
   ],
   "source": [
    "# Example of how GraphRAG would use your custom vector store\n",
    "def simulate_graphrag_pipeline():\n",
    "    \"\"\"Simulate how GraphRAG would use the custom vector store.\"\"\"\n",
    "    print(\"üöÄ Simulating GraphRAG pipeline with custom vector store...\\n\")\n",
    "\n",
    "    # 1. GraphRAG creates vector store using factory\n",
    "    schema = IndexSchema(index_name=\"graphrag_entities\")\n",
    "\n",
    "    store = create_vector_store(\n",
    "        VectorStoreConfig(\n",
    "            type=CUSTOM_VECTOR_STORE_TYPE,\n",
    "            custom_config_option=\"example_value\",  # type: ignore\n",
    "        ),\n",
    "        schema,\n",
    "    )\n",
    "    store.connect()\n",
    "    store.create_index()\n",
    "    print(\"‚úÖ Step 1: Vector store created and connected\")\n",
    "\n",
    "    # 2. During indexing, GraphRAG loads extracted entities\n",
    "    entity_documents = [\n",
    "        VectorStoreDocument(\n",
    "            id=f\"entity_{i}\",\n",
    "            vector=create_mock_embedding(),\n",
    "        )\n",
    "        for i in range(10)\n",
    "    ]\n",
    "\n",
    "    store.load_documents(entity_documents)\n",
    "    print(f\"‚úÖ Step 2: Loaded {len(entity_documents)} entity documents\")\n",
    "\n",
    "    # 3. During query time, GraphRAG searches for relevant entities\n",
    "    query_embedding = create_mock_embedding()\n",
    "    relevant_entities = store.similarity_search_by_vector(query_embedding, k=5)\n",
    "\n",
    "    print(f\"‚úÖ Step 3: Found {len(relevant_entities)} relevant entities for query\")\n",
    "\n",
    "    # 4. GraphRAG uses these entities for context building\n",
    "    context_entities = [result.document for result in relevant_entities]\n",
    "\n",
    "    print(\"‚úÖ Step 4: Context built using retrieved entities\")\n",
    "\n",
    "    return context_entities\n",
    "\n",
    "\n",
    "# Run the simulation\n",
    "context = simulate_graphrag_pipeline()\n",
    "print(f\"\\nüéØ Retrieved {len(context)} entities for context building\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Testing and Validation\n",
    "\n",
    "Let's create a comprehensive test suite to ensure our vector store works correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running comprehensive vector store tests...\n",
      "\n",
      "Test 1: Basic functionality\n",
      "Connecting to in-memory vector store...\n",
      "Connected successfully!\n",
      "Creating index: test_collection\n",
      "Index created successfully!\n",
      "Loading 2 documents...\n",
      "Successfully loaded 2 documents!\n",
      "‚úÖ Basic functionality test passed\n",
      "\n",
      "Test 2: Search functionality\n",
      "‚úÖ Search functionality test passed\n",
      "\n",
      "Test 3: Search by ID\n",
      "‚úÖ Search by ID test passed\n",
      "\n",
      "Test 5: Error handling\n",
      "‚úÖ Error handling test passed\n",
      "\n",
      "üéâ All tests passed! Your custom vector store is working correctly.\n"
     ]
    }
   ],
   "source": [
    "def test_custom_vector_store():\n",
    "    \"\"\"Comprehensive test suite for the custom vector store.\"\"\"\n",
    "    print(\"üß™ Running comprehensive vector store tests...\\n\")\n",
    "\n",
    "    # Test 1: Basic functionality\n",
    "    print(\"Test 1: Basic functionality\")\n",
    "    store = create_vector_store(\n",
    "        VectorStoreConfig(\n",
    "            type=CUSTOM_VECTOR_STORE_TYPE,\n",
    "            custom_config_option=\"example_value\",  # type: ignore\n",
    "        ),\n",
    "        schema,\n",
    "    )\n",
    "    store.connect()\n",
    "    store.create_index()\n",
    "    # Load test documents\n",
    "    test_docs = sample_documents[:2]\n",
    "    store.load_documents(test_docs)\n",
    "\n",
    "    assert len(store.documents) == 2, \"Should have 2 documents\"\n",
    "    assert len(store.vectors) == 2, \"Should have 2 vectors\"\n",
    "    print(\"‚úÖ Basic functionality test passed\")\n",
    "\n",
    "    # Test 2: Search functionality\n",
    "    print(\"\\nTest 2: Search functionality\")\n",
    "    query_vec = create_mock_embedding()\n",
    "    results = store.similarity_search_by_vector(query_vec, k=5)\n",
    "\n",
    "    assert len(results) <= 2, \"Should not return more results than documents\"\n",
    "    assert all(isinstance(r, VectorStoreSearchResult) for r in results), (\n",
    "        \"Should return VectorStoreSearchResult objects\"\n",
    "    )\n",
    "    assert all(-1 <= r.score <= 1 for r in results), (\n",
    "        \"Similarity scores should be between -1 and 1\"\n",
    "    )\n",
    "    print(\"‚úÖ Search functionality test passed\")\n",
    "\n",
    "    # Test 3: Search by ID\n",
    "    print(\"\\nTest 3: Search by ID\")\n",
    "    found_doc = store.search_by_id(\"doc_1\")\n",
    "    assert found_doc.id == \"doc_1\", \"Should find correct document\"\n",
    "\n",
    "    try:\n",
    "        store.search_by_id(\"nonexistent\")\n",
    "        assert False, \"Should raise KeyError for nonexistent ID\"\n",
    "    except KeyError:\n",
    "        pass  # Expected\n",
    "\n",
    "    print(\"‚úÖ Search by ID test passed\")\n",
    "\n",
    "    # Test 4: Error handling\n",
    "    print(\"\\nTest 5: Error handling\")\n",
    "    disconnected_store = create_vector_store(\n",
    "        VectorStoreConfig(\n",
    "            type=CUSTOM_VECTOR_STORE_TYPE,\n",
    "            custom_config_option=\"example_value\",  # type: ignore\n",
    "        ),\n",
    "        IndexSchema(index_name=\"test2\"),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        disconnected_store.load_documents(test_docs)\n",
    "        assert False, \"Should raise error when not connected\"\n",
    "    except RuntimeError:\n",
    "        pass  # Expected\n",
    "\n",
    "    try:\n",
    "        disconnected_store.similarity_search_by_vector(query_vec)\n",
    "        assert False, \"Should raise error when not connected\"\n",
    "    except RuntimeError:\n",
    "        pass  # Expected\n",
    "\n",
    "    print(\"‚úÖ Error handling test passed\")\n",
    "\n",
    "    print(\"\\nüéâ All tests passed! Your custom vector store is working correctly.\")\n",
    "\n",
    "\n",
    "# Run the tests\n",
    "test_custom_vector_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Congratulations! You've successfully learned how to implement and register a custom vector store with GraphRAG. Here's what you accomplished:\n",
    "\n",
    "### What You Built\n",
    "\n",
    "- ‚úÖ **Custom Vector Store Class**: Implemented `SimpleInMemoryVectorStore` with all required methods\n",
    "- ‚úÖ **Factory Integration**: Registered your vector store with `VectorStoreFactory`\n",
    "- ‚úÖ **Comprehensive Testing**: Validated functionality with a full test suite\n",
    "- ‚úÖ **Configuration Examples**: Learned how to configure GraphRAG to use your vector store\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Interface Compliance**: Always implement all methods from `VectorStore`\n",
    "2. **Factory Pattern**: Use `VectorStoreFactory.register()` to make your vector store available\n",
    "3. **Testing**: Validate your implementation thoroughly before production use\n",
    "4. **Configuration**: Use YAML or environment variables for flexible configuration\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "For production use, consider:\n",
    "\n",
    "- **Persistence**: Add data persistence mechanisms\n",
    "- **Scalability**: Use optimized vector search libraries (FAISS, HNSW)\n",
    "- **Error Handling**: Implement robust error handling and logging\n",
    "- **Performance**: Add caching, batching, and connection pooling\n",
    "- **Security**: Implement authentication and authorization\n",
    "- **Monitoring**: Add metrics and health checks\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [GraphRAG Documentation](https://microsoft.github.io/graphrag/)\n",
    "- [Vector Store Examples](https://github.com/microsoft/graphrag/tree/main/packages/graphrag-vectors)\n",
    "- [GraphRAG GitHub Repository](https://github.com/microsoft/graphrag)\n",
    "\n",
    "Happy building! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
